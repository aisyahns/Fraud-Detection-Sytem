{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import scikitplot as skplt\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from scipy import stats\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('paysim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
      "count  6.362620e+06  6.362620e+06   6.362620e+06    6.362620e+06   \n",
      "mean   2.433972e+02  1.798619e+05   8.338831e+05    8.551137e+05   \n",
      "std    1.423320e+02  6.038582e+05   2.888243e+06    2.924049e+06   \n",
      "min    1.000000e+00  0.000000e+00   0.000000e+00    0.000000e+00   \n",
      "25%    1.560000e+02  1.338957e+04   0.000000e+00    0.000000e+00   \n",
      "50%    2.390000e+02  7.487194e+04   1.420800e+04    0.000000e+00   \n",
      "75%    3.350000e+02  2.087215e+05   1.073152e+05    1.442584e+05   \n",
      "max    7.430000e+02  9.244552e+07   5.958504e+07    4.958504e+07   \n",
      "\n",
      "       oldbalanceDest  newbalanceDest       isFraud  isFlaggedFraud  \n",
      "count    6.362620e+06    6.362620e+06  6.362620e+06    6.362620e+06  \n",
      "mean     1.100702e+06    1.224996e+06  1.290820e-03    2.514687e-06  \n",
      "std      3.399180e+06    3.674129e+06  3.590480e-02    1.585775e-03  \n",
      "min      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n",
      "25%      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n",
      "50%      1.327057e+05    2.146614e+05  0.000000e+00    0.000000e+00  \n",
      "75%      9.430367e+05    1.111909e+06  0.000000e+00    0.000000e+00  \n",
      "max      3.560159e+08    3.561793e+08  1.000000e+00    1.000000e+00  \n",
      "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
      "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
      "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
      "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
      "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "1  M2044282225             0.0             0.0        0               0  \n",
      "2   C553264065             0.0             0.0        1               0  \n",
      "3    C38997010         21182.0             0.0        1               0  \n",
      "4  M1230701703             0.0             0.0        0               0  \n"
     ]
    }
   ],
   "source": [
    "print(raw_data.describe())\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df = raw_data.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n",
    "                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modification for step feature\n",
    "df['step'] = df['step'] % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop feature irrelevant\n",
    "df.drop(['nameOrig', 'nameDest'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature values \n",
    "df = df[(df['type'] == 'CASH_OUT') | (df['type'] == 'TRANSFER')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding feature type\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "typeTrans = [['CASH_OUT'] , ['TRANSFER']]\n",
    "oencoder = OrdinalEncoder()\n",
    "oencoder.fit(typeTrans)\n",
    "df['type_en'] = oencoder.transform(df['type'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>type_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>229133.94</td>\n",
       "      <td>15325.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5083.00</td>\n",
       "      <td>51513.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>215310.30</td>\n",
       "      <td>705.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22425.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>311685.89</td>\n",
       "      <td>10835.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6267.00</td>\n",
       "      <td>2719172.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362615</th>\n",
       "      <td>23</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362616</th>\n",
       "      <td>23</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362617</th>\n",
       "      <td>23</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68488.84</td>\n",
       "      <td>6379898.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362618</th>\n",
       "      <td>23</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362619</th>\n",
       "      <td>23</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6510099.11</td>\n",
       "      <td>7360101.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2770409 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step      type      amount  oldBalanceOrig  newBalanceOrig  \\\n",
       "2           1  TRANSFER      181.00          181.00             0.0   \n",
       "3           1  CASH_OUT      181.00          181.00             0.0   \n",
       "15          1  CASH_OUT   229133.94        15325.00             0.0   \n",
       "19          1  TRANSFER   215310.30          705.00             0.0   \n",
       "24          1  TRANSFER   311685.89        10835.00             0.0   \n",
       "...       ...       ...         ...             ...             ...   \n",
       "6362615    23  CASH_OUT   339682.13       339682.13             0.0   \n",
       "6362616    23  TRANSFER  6311409.28      6311409.28             0.0   \n",
       "6362617    23  CASH_OUT  6311409.28      6311409.28             0.0   \n",
       "6362618    23  TRANSFER   850002.52       850002.52             0.0   \n",
       "6362619    23  CASH_OUT   850002.52       850002.52             0.0   \n",
       "\n",
       "         oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  type_en  \n",
       "2                  0.00            0.00        1               0      1.0  \n",
       "3              21182.00            0.00        1               0      0.0  \n",
       "15              5083.00        51513.44        0               0      0.0  \n",
       "19             22425.00            0.00        0               0      1.0  \n",
       "24              6267.00      2719172.89        0               0      1.0  \n",
       "...                 ...             ...      ...             ...      ...  \n",
       "6362615            0.00       339682.13        1               0      0.0  \n",
       "6362616            0.00            0.00        1               0      1.0  \n",
       "6362617        68488.84      6379898.11        1               0      0.0  \n",
       "6362618            0.00            0.00        1               0      1.0  \n",
       "6362619      6510099.11      7360101.63        1               0      0.0  \n",
       "\n",
       "[2770409 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['type'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>type_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>229133.94</td>\n",
       "      <td>15325.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5083.0</td>\n",
       "      <td>51513.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>215310.30</td>\n",
       "      <td>705.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22425.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>311685.89</td>\n",
       "      <td>10835.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6267.0</td>\n",
       "      <td>2719172.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    step     amount  oldBalanceOrig  newBalanceOrig  oldBalanceDest  \\\n",
       "2      1     181.00           181.0             0.0             0.0   \n",
       "3      1     181.00           181.0             0.0         21182.0   \n",
       "15     1  229133.94         15325.0             0.0          5083.0   \n",
       "19     1  215310.30           705.0             0.0         22425.0   \n",
       "24     1  311685.89         10835.0             0.0          6267.0   \n",
       "\n",
       "    newBalanceDest  isFraud  isFlaggedFraud  type_en  \n",
       "2             0.00        1               0      1.0  \n",
       "3             0.00        1               0      0.0  \n",
       "15        51513.44        0               0      0.0  \n",
       "19            0.00        0               0      1.0  \n",
       "24      2719172.89        0               0      1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SelectKBest(score_func = f_classif, k= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['isFraud']\n",
    "X = df.drop(['isFraud', 'oldBalanceDest', 'newBalanceDest', 'isFlaggedFraud', 'amount', 'oldBalanceOrig', 'newBalanceOrig'], axis = 1)\n",
    "#X = df.drop(['isFraud'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362615</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362616</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362617</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362618</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362619</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2770409 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step  type_en\n",
       "2           1      1.0\n",
       "3           1      0.0\n",
       "15          1      0.0\n",
       "19          1      1.0\n",
       "24          1      1.0\n",
       "...       ...      ...\n",
       "6362615    23      0.0\n",
       "6362616    23      1.0\n",
       "6362617    23      0.0\n",
       "6362618    23      1.0\n",
       "6362619    23      0.0\n",
       "\n",
       "[2770409 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.29001755e+03 1.39016379e+04 3.80694276e+05 1.12365491e+04\n",
      " 6.20175363e+02 2.23308306e+02 5.39161938e+03 4.98958834e+03]\n",
      "[[1.8100000e+02 1.8100000e+02 0.0000000e+00]\n",
      " [1.8100000e+02 1.8100000e+02 0.0000000e+00]\n",
      " [2.2913394e+05 1.5325000e+04 0.0000000e+00]\n",
      " [2.1531030e+05 7.0500000e+02 0.0000000e+00]\n",
      " [3.1168589e+05 1.0835000e+04 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "fit = test.fit(df.drop(['isFraud'], axis = 1), df['isFraud'])\n",
    "print(fit.scores_)\n",
    "features = fit.transform(df.drop(['isFraud'], axis = 1))\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15dc0d39cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(pd.concat([X, y], axis = 1).corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15dc0caca30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAFGCAYAAADO91C/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxcVZn/8c83gSSQAAERBtnCEozsS9gXA+KCC4ugrCPgaHQUAf3hNuIooqOMjqIQwaAsoiIjIAgygCIhYQlkISSETTYFAQGFELZAur+/P86pUCmqu6uTvnWrup43r/vqqntv3edW0amnn3PPPUe2CSGEEFrJkLJPIIQQQqgVySmEEELLieQUQgih5URyCiGE0HIiOYUQQmg5kZxCCCG0nEhOIYQQlpmkcyU9JemuHrZL0o8kPSBprqTtGzluJKcQQgjL43zgPb1s3w8Ym5eJwFmNHDSSUwghhGVmeyrwz152OQD4uZPpwGhJ6/R13EhOIYQQirQu8GjV88fyul6tUNjphH557ZmHmj6O1Mh192p2SABWHFrOr93woSs2PeYQqekxAbq6u0uJu/DVl0uJO3rEyKbHfK27q+kxKxa88OBy/WL15/tm2Js3+QSpOa5isu3J/QhX71z7jB/JKYQQOk0/EmtORP1JRrUeA9aver4e8HhfL4pmvRBC6DTubnxZfr8DPpJ77e0CLLD9RF8visophBA6zQA2+0q6CJgArCnpMeBrwIoAts8GrgbeCzwAvAQc28hxIzmFEEKHcdfigTuWfXgf2w18ur/HjeQUQgidZmCa6woVySmEEDpNiT0NGxXJKYQQOk0bVE7RW68fJJ0oaeWyzyOEEJZLd3fjS0kiOfXPiUAkpxBCW7O7G17KEs16PZA0Evhf0g1jQ4HfAG8BbpD0jO29Jb0LOAUYDjwIHGv7BUmPABcDe+fDHWH7gWa/hxBCqGsAe+sVJSqnnr0HeNz2Nra3BE4n3dW8d05MawInA/va3h6YCXyu6vXP294JODO/NoQQWkN3V+NLSSI59WwesK+k0yTtaXtBzfZdgM2BmyXNAY4GNqzaflHVz13rBZA0UdJMSTN/+vOL6u0SQggDr7kjRCyTaNbrge37Je1AurP525Kuq9lFwB96uQHNPTyujrFkzKoyBn4NIXSoEjs6NCoqpx5Iegvwku1fAN8DtgcWAqvkXaYDu0vaNO+/sqTNqg5xaNXPW5tz1iGE0IConNraVsB3JXUDrwH/Tmqe+z9JT+TrTscAF0kanl9zMnB/fjxc0m2kPwB6Hd4jhBCaqg0qp0hOPbB9LXBtzeqZwBlV+/wJ2LGHQ0yyfUpBpxdCCMvM3a+VfQp9iuQUQgidJiqnzmR7TNnnEEIIPWqD4YsiOYUQQqeJgV9DCCG0nKicQgghtJw2GL4oklMIIXSa6BARGjVy3b2aHvPFv01tekyAd2zz8VLi/vnFJ5oe84TVtm96TID3Dakdbas5Dn/p6VLiPrOo+e/3K6N3anrMARPJKYQQQquxo0NECCGEVhOVUwghhJYTvfVCCCG0nOitF0IIoeVEs14IIYSWE816IYQQWk5UTiGEEFpOGySnmAm3QJIOlLR52ecRQghLaYOZcCM5FetAIJJTCKG1dC1ufCnJoE1Oki6XNEvSfEkT87oXJJ2W1/9R0k6Spkh6SNL+eZ8Rks6TNE/SHZL2zuuPkXRm1fGvkjSh6rjfknSnpOmS1pa0G7A/aar3OZI2afqHEEII9XR3N76UZNAmJ+CjtncAxgPHS3oTMBKYktcvBL4JvBM4CPhGft2nAWxvBRwOXCBpRB+xRgLTbW8DTAU+bvsW4HfA521va/vBgX17IYSwjNqgWW8wd4g4XtJB+fH6wFjgVeCavG4esMj2a5LmAWPy+j2AMwBs3yvpL8BmfcR6FbgqP55FSnh9yhXdRIChQ0czZOjIRl4WQgjLpw06RAzK5JSb2/YFdrX9kqQpwAjgNdvOu3UDiwBsd0uqfBbq4bCLWbrSrK6mqo/bRYOfq+3JwGSAYcPXcx+7hxDCwGiD5DRYm/VWA57NiWkcsEs/XjsVOBJA0mbABsB9wCPAtpKGSFofaGS8/IXAKv058RBCKFxXV+NLAyS9R9J9kh6Q9KU621eTdGW+Lj9f0rF9HXOwJqdrgBUkzQVOBab347U/Bobmpr6LgWNsLwJuBh4mNQd+D5jdwLF+DXw+d6yIDhEhhNYwgB0iJA0FJgH7kXonH17nFppPA3fn6/ITgP+RNKy34w7KZr2cTPars2lU1T5fr3nNqPzzFeCYOsc0uaKqs636uJcAl+THNxNdyUMIrWZgOzrsBDxg+yEASb8GDgDuro4IrCJJpO/hf5IulfRosFZOIYQQetKPyknSREkzq5aJNUdbF3i06vljeV21M4G3AY+TWp9OsHvPkIOycgohhNALN97/qrrjVg/qdSKrDfBuYA6wD7AJ8AdJ02w/39NBo3IKIYROM7A34T5Gul2nYj1ShVTtWOAyJw+Qrt+P6+2gkZxCCKHTDOzwRTOAsZI2yp0cDiMNQFDtr8A7ACStDbwVeKi3g0azXgghdBh3D9xtlbYXSzoOuBYYCpxre76kT+btZ5N6TZ+fe0EL+KLtZ3o7biSnEELoNAN8E67tq4Gra9adXfX4ceBd/TlmJKcQQug0MRNuaNSKQ5v/v+Id23y86TEBrr/znFLivnbZGU2PudaJlzc9JsBpQ4aWEvc7o/szGMvAmaTmj6t82vOzmh6z4rPLe4ABbNYrSiSnEELoNIvLm6epUZGcQgih0/TjPqeyRHIKIYRO0wajkkdyCiGEThPXnEIIIbSc6K0XQgih5UTlFEIIodV4cWOTCJYpklMIIXSaNmjWK2TgV0kv9LD+fEmH5MdT8rS+cyTdU2eOkHqvnyJp/ECfbw+xhkk6XdKDkv4s6QpJ6/Wy/9WSRjfj3EIIYbl0u/GlJGVXTkfanilpDeBBSefbfrXkc6r4L2AVYDPbXXnO+8sk7ZxnxQUgz+wo2+8t60RDCKFf2qAr+XJXTpI+J+muvJxYs02SzpR0t6TfA2v1cJhRwItAV37dWXnGxfmSTukhbt19JD0i6RRJsyXNkzQurx8l6by8bq6kg/P6d0m6Ne//m7zfyqT5Rz5ruwvA9nnAImAfSWNytfdjYDawfo67Zj7mVyXdK+kPki6SdNKyfr4hhDDgBnvlJGkH0pf4zqRh0G+TdGPVLgeR5u3YClibNKf8uVXbfylpETAWOLGSCICv2P6npKHA9ZK2tj23Jnxv+zxje3tJnwJOAj4GfBVYYHurfO6r52RyMrCv7RclfRH4HHA58Nc6szTOBLYAHszv61jbn8rHq3wm44GDge1In+9soO4gXLkpcyLAsBXXYIUVVqm3WwghDKw2uOa0vM16ewC/tf0igKTLgD2rtu8FXJSTzuOS/lTz+kqz3puBWyRdY/svwIfzF/cKwDrA5kBtcuptn8vyz1nAB/PjfUmTYAFg+1lJ78+vuzknl2HAraREW+9Phur1f7E9vYfP5ArbL+fP5Mo6+1TOYcn0xyNXHtP6fTtDCINCJ/TWqzd3fK0+v3RtPy1pNrCzpCGkamfHnEDOB0YsFVTaqI99FuWfXbz+HuslHAF/sH14zfFHAhtKWsX2wqpN2wOVZPNiD2+nkc8khBDK0wb3OS3vNaepwIGSVs5f6AcB02q2HyZpqKR1gL3rHSRf49mO1Fy2KumLf0Gezne/Oi9pZJ9a1wHHVcVcHZgO7C5p08p5SNosV4IXAN/PzYZI+giwMlBb/dW6CfiApBGSRgHva+DcQgiheQb7NSfbs3PVcnte9VPbd1SuvwC/BfYB5gH3AzfWHOKXkl4GhgPn254FIOkOYD5pjvmb68S9s6996vgmMEnSXaSK6hTbl0k6BrhI0vC838n5XL8MfA+4X1I3cC9wkG1Xvb96n8kMSb8D7gT+QrpOtaCB8wshhObogGtO2P4+8P2adaPyT1NVrdTsM6GXYx7T12t62WdM1eOZwIT8+AXg6Dr7/wnYsc76RcBn8lK77RFgy57iAt+z/fVcEU4F/qfeuYYQQinaoFmv7PucBqvJkjYnXQe7wPbssk8ohBAqvLgDKqfwRraPKPscQgihR21wE24kpxBC6DTRrBdCCKHlRHIKIYTQaqqGB21ZkZxCCKHTROUUGjV86IpNj/nnF59oekyA1y47o5S4K37wDXcFFG7o537X9JgAXSXdx3L6q/eXEnftYas2PeZDrz7Z9JgDJXrrhRBCaD1ROYUQQmg5rV84RXIKIYRO46icQgghtJxITiGEEFpONOuFEEJoNV7c+pXT8s7nFEIIoc242w0vjZD0Hkn3SXpA0pd62GeCpDmS5kuqnT7pDaJyCiGETjOAzXp5QtZJwDuBx4AZkn5n++6qfUYDPwbeY/uvktbq67ilVU6SjpH0dFUmvSTPf9TXa85s4jkeKGmupHslzZN0YC/7fjLPlhtCCC3N3Y0vDdgJeMD2Q7ZfBX4NHFCzzxHAZbb/CmD7qb4OWnaz3sW2t7W9BfAqcGjJ57OEpG1IM+EeYHscsD/wPUlb19l3Bdtn2/55s88zhBD6rbvxRdJESTOrlok1R1sXeLTq+WN5XbXNgNUlTZE0q5E/5BtOTpLGSLpH0jm50rlO0kqSNpF0TQ44TdI4SUMlPaRktKRuSXvl40yTtGnNsVcARgLP5ucfkHSbpDsk/VHS2nXOp+4+kr4u6dz8ITwk6fiq13wkV0J3Srowr3uzpEslzcjL7nn3k4D/sv0wQP75beDz+XVTJP1Xbjs9Icc9KW/bMce5VdJ389TwIYTQEry4H4s92fb4qmVyzeFUL0TN8xWAHYD3Ae8Gvipps97Osb+V01hgUq50ngMOBiYDn7G9A+kL/ce2u4D7gc2BPYBZwJ6ShgPr2X4gH+9QSXOAvwFrAFfm9TcBu9jejlQifqHOufS2zzjSB7AT8DVJK0raAvgKsI/tbYAT8r4/BH5ge8f8fn6a12+Rz7vazLy+YrTtt9uunYb9POCTtncFuuqcO7D0XySLXlvQ024hhDCgBrhZ7zFg/arn6wGP19nnGtsv2n4GmAps09tB+9sh4mHbc/LjWcAYYDfgN9KS5Dk8/5wG7AVsRKo4Pg7cCMyoOt7Fto9TevEkUlXynfzmLpa0DjAMeLjOufS2z+9tLwIWSXoKWBvYB7gkfzDY/mfed19g86rzX1XSKqS/Bmqzf+26i2tPKl/4W8X2LXnVr4D31zl/8l8gkwHWWGVs6/ftDCEMCgM8LvAMYKykjUiFxmGka0zVrgDOzK1kw4CdgR/0dtD+Vk6Lqh53kaqd5/J1o8rytrx9GrAnqXq5GhgNTCBlzKU4TS5yJSmZAZwBnGl7K+ATwIg659LbPrXnuQL1kw2kz2DXqvNf1/ZCYD4wvmbf7YG7q56/WOd49UrcEEJoGQNZOdleDBwHXAvcA/yv7fm5k9gn8z73ANcAc4HbgZ/a7vVyx/J2iHgeeFjShwDyNaZKqXYbqarqtv0KMIeURKb1cKw9gAfz49VIGRjg6B72b2SfatcDH5b0pnyua+T115E+WPL6bfPD7wFfljQmrx8D/AdQ24S3FNvPAgsl7ZJXHdbAuYUQQvNYjS+NHM6+2vZmtjex/a287mzbZ1ft813bm9ve0vbpfR1zIHrrHQn8m6Q7SdXGAflEFpF6cEzP+00DVgHmVb320NyVfC6wHXBqXv91UlPhNOCZHuI2ss8StucD3wJuzOf6/bzpeGB87sBwN1DJ9HOALwJXSrqXVNl9oapZszf/BkyWdCupkooLSiGEljHA15wKoXaYrrfdSBpl+4X8+EvAOrZP6O01ZVxzKmOCQ4AH//vdpcQtY7LBNce8s+kxobxpuNcduWYpccuYbHDmPx/se6eCvPDSw8t1+eDx3fZu+BfkLbfcUMqlihghohjvk/Rl0uf7F+CYck8nhBBe5wab68oUyakAti+mTk++EEJoBWU21zUqklMIIXQYd0flFEIIocW0Q1eDSE4hhNBhonIKIYTQcrq7IjmFBg1R839ZTlht+6bHBFjrxMtLiTv0c79resxnHvlD02MC+MXnSom75uaHlBL36Vea/343H71B02MOlKicQgghtJzoSh5CCKHlRFfyEEIILac7KqcQQgitprur7EnQ+xbJKYQQOkzc5xRCCKHlRG+9EEIILSeuOYUQQmg57dCVfECvikl6oYf150s6JD+eIum+PMngPZImNnDcKZJqp0wvRNX5zZV0r6QzJY1exmMdI+ktA32OIYSwPOzGl7KU1WXjSNvbArsDp0kaVtJ59ORI21sDWwOLgCuW8TjHAJGcQggtpat7SMNLWZY5sqTPSborLyfWbFOuOO6W9HtgrR4OMwp4EejKrztL0kxJ8yWd0kPcuvtIekTSKZJmS5onaVxeP0rSeXndXEkH5/XvknRr3v83kkbVxrL9KvAFYANJ2+TXHSXp9lz5/UTS0Lycnz+LeZI+myvF8cAv874r9e8TDiGEYrRD5bRM15wk7QAcC+wMCLhN0o1VuxwEvBXYClgbuBs4t2r7LyUtAsYCJ9ruyuu/YvufkoYC10va2vbcmvC97fOM7e0lfQo4CfgY8FVgge2t8rmvLmlN4GRgX9svSvoi8DngG7Xv1XaXpDuBcZJeBQ4Fdrf9mqQfA0cC84F1bW+ZY4y2/Zyk44CTbM/s4XOcCEwEGDl8LUYMW63+Bx5CCAOoHTpELGvltAfwW9sv2n4BuAzYs2r7XsBFtrtsPw78qeb1lWazDYCTJG2Y139Y0mzgDmALYPM6sXvb57L8cxYwJj/eF5hU2cH2s8Au+XU3S5oDHA1sSM8q/yffAewAzMivewewMfAQsLGkMyS9B3i+l2MtYXuy7fG2x0diCiE0i62Gl7Isa2+9Rs64z4LQ9tM50ewsaQip2tnR9rOSzgdGLBVU2qiPfRbln128/t5U51wE/MH24X2dY67QtgLuITVPXmD7y3X22wZ4N/Bp4MPAR/s6dgghlGEwV05TgQMlrSxpJKkZb1rN9sPytZh1gL3rHUTSysB2wIPAqqTrTwskrQ3sV+cljexT6zrguKqYqwPTgd0lbVo5D0mb1Tm/FYFvA4/mpsPrgUMkrZW3ryFpw9xMOMT2paRmxMpcFAuBVRo4xxBCaBr3YynLMlVOtmfnquX2vOqntu/Q63MS/RbYB5gH3A/cWHOIX0p6GRgOnG97FoCkO0jXbx4Cbq4T986+9qnjm8AkSXeRKqpTbF8m6RjgIknD834n53OtnN+ifH5/BA7I8e+WdDJwXa70XiNVSi8D5+V1AJXK6nzg7Pxed7X9cgPnG0IIhSqzF16j5HYYZKkDrLnqZk3/H3HS6js1OyQA33y6kb8pBt7QIc3/BxmTDTbHsKHNH09g41HrND1mxe2P37hc7XLT/uWQhr9v9nzyklLaAGOEiBBC6DBuqNtAuSI5hRBCh+lugwazSE4hhNBhuqNyCiGE0Gq6IjmFEEJoNXHNKYQQQsvpLvsEGhDJqUV0dTf/1+V9QxY0PSbAaUOGlhK3y83/jMvq0q2RyzTLy3Ibqta/f2agrLXCG8aKbhsD/S8hD9v2Q2Ao6b7X7/Sw346kQRAOtX1Jb8fsnN+kEEIIQGrWa3TpSx7ibRJpxJ7NgcMlvWFc1LzfacC1jZxjJKcQQugw3Wp8acBOwAO2H8rTDP2aPKpOjc8AlwJPNXLQSE4hhNBhulDDSwPWBR6tev5YXreEpHVJY7Ce3eg5RnIKIYQO092PRdLEPMFrZZlYc7h6Gaz2Nt/TgS9Wzd3Xp+gQEUIIHaZbjXcltz0ZmNzLLo8B61c9Xw94vGaf8cCv8+DgawLvlbTY9uU9HTSSUwghdJgBHr1oBjA2z7f3N+Aw4Iil4tkbVR7nGS2u6i0xQSSnEELoOAPZldz2YknHkXrhDQXOtT1f0ifz9oavM1WL5BRCCB1mcT+a9Rph+2rg6pp1dZOS7WMaOWbTO0RIOkbS05LmSJov6ZI8I25frzmzyed3h6Q/S7pW0m7LeKxtJb13oM8xhBCWRzvMhFtWb72LbW9rewvgVeDQks6jJxfb3s72WOA7wGWS3rYMx9kWiOQUQmgpA3yfUyH6TE6Sxki6R9I5udK5TtJKkjaRdI2kWZKmSRonaaikh5SMltQtaa98nGmSNq059grASODZ/PwDkm7LVcsfJa1d53zq7iPp65LOlTQln8PxVa/5iKS5ku6UdGFe92ZJl0qakZfd671/2zeQeqpMzK97w/vO6z8k6a4cY6qkYcA3gENzldhqCTiE0KH605W8LI1WTmOBSbnSeQ44mPSF/RnbOwAnAT/OfdjvJw1hsQcwC9hT0nBgPdsP5OMdKmkOqWfHGsCVef1NwC62tyPdZfyFOufS2z7jgHeT7lj+mqQVJW0BfAXYx/Y2wAl53x8CP7C9Y34/P+3l/c/Ox6be+87r/xN4d46xf75T+j95vUq8uJfjhxBC07RDs16jHSIetj0nP54FjAF2A36j1y+sDc8/pwF7ARsB3wY+DtxI6m5YcbHt45RePAn4PKn5bD3gYknrAMOAh+ucS2/7/N72ImCRpKeAtYF9gEtsPwNg+595332BzavOf1VJq/Tw/gUgaVQv7/tm4HxJ/wtc1sNxlj5oupltIsBKw97M8BVXbeRlIYSwXMpsrmtUo5XToqrHXaRq57lcEVSWyjWZacCepOrlamA0MAGYWntQ2yZVTXvlVWcAZ9reCvgEMKLOufS2T+15rkBKLPX+ABgC7Fp1/uvaXtjD+98OuCe/pu77tv1J4GTSzWhzJL2ph2NVv//JtsfbHh+JKYTQLIv7sZRlWTtEPA88LOlDAPka0zZ5222k6qLb9ivAHFISmdbDsfYAHsyPVyM19QEc3cP+jexT7Xrgw5VkIWmNvP464LjKTpK2rfdiSW8nVTfn2O7xfUvaxPZttv8TeIaUpBYCPVVjIYRQCqvxpSzL01vvSODfJN0JzCePQpub1R4lzdkBKSmtAsyrem2lk8BcUlVyal7/dVKT2TTSF3w9jeyzhO35wLeAG/O5fj9vOh4YnztK3A18ss753Q/8B3Cw7Xt6e9/AdyXNk3QXqUq8E7iB1HQYHSJCCC2jHTpEKLWshbKtPmrTpv+PmPrmZekdv/z2evqevncqQBmTDT5zd6/zqRWmrMkG1xrzrlLiDh3S/Ltidhk9tukxK6766++Xq6Y5c/2jGv6+Oe7RX5RSP8UIESGE0GHaoSSJ5BRCCB2mHXrrRXIKIYQOU2YvvEZFcgohhA4TzXohhBBaTjTrhRBCaDlldhFvVCSnFrHw1ZebHvPwl55uekyA74zepZS4p796f9Njrrn5IU2PCTBU5Uw48NQj15USd9y45n/Od79UOxN5+4hmvRBCCC1ncRukp0hOIYTQYVo/NUVyCiGEjhPXnEIIIbSc6K0XQgih5XS3QcNeJKcQQugwrZ+aIjmFEELHid56IYQQWk7rp6blm2yw5Um6pY/tj+QJAufkZbeCzuOFIo4bQgjLoh0mGxzUlZPtRpLN3rbrzqgraajtrgE+rRBCKFU7dIgY7JXTC/nnOpKm5uroLkl79vKaCZJukPQr8tTyki6XNEvSfEkTa4+fHx8i6fz8eCNJt0qaIenU2hghhFAm92Mpy6CunKocAVxr+1uShgIrV227QVIXsMj2znndTsCWth/Ozz9q+5+SVgJmSLrU9j96ifdD4CzbP5f06YF+MyGEsDziJtzWMQM4V9KKwOW251Rtq9esd3tVYgI4XtJB+fH6wFigt+S0O3BwfnwhcFq9nXIVNhFAQ1djyJCRDb2ZEEJYHl3RrNcabE8F9gL+Blwo6SN9vOTFygNJE4B9gV1tbwPcAYyoHLrqNSNYWp//921Ptj3e9vhITCGEZunGDS9l6YjkJGlD4Cnb5wA/A7bvx8tXA561/ZKkcUD1fA9/l/Q2SUOAg6rW3wwclh8fuRynHkIIA64drjl1RHICJgBzJN1Bam77YT9eew2wgqS5wKnA9KptXwKuAv4EPFG1/gTg05JmkJJbCCG0jHaonAb1NSfbo/LPC4AL6mwfU2fdFGBK1fNFwH49HP8S4JI66x8Gdq1a9Z1+nXgIIRSoHTpEdErlFEIIIevCDS+NkPQeSfdJekDSl+psP1LS3LzcImmbvo45qCunEEIIb+QBbK7Lt+dMAt4JPEa63eZ3tu+u2u1h4O22n5W0HzAZ2PmNR3tdJKcQQugwA9ystxPwgO2HACT9GjgAWJKcbFcPJTcdWK+vg0azXgghdJhuu+FF0kRJM6uWiTWHWxd4tOr5Y3ldT/4N+L++zjEqpxBC6DD9adSzPZnUDNeTevPq1g0haW9Sctqjr7iRnEIIocMMcBfxx0gj51SsBzxeu5OkrYGfAvv1MfwbEMmpZYwe0fwRIp5ZtKDpMQEm6cFS4q49bNWmx3z6leeaHrNM48YdUkrce+99wx0dhXvLJnXvMGkLAzx80QxgrKSNSKPwHEYaz3QJSRsAlwH/avv+Rg4aySmEEDrMQFZOthdLOg64FhgKnGt7vqRP5u1nA/8JvAn4sSSAxbbH93bcSE4hhNBhBrIrOYDtq4Gra9adXfX4Y8DH+nPMSE4hhNBh2mGEiEhOIYTQYezWnzIjklMIIXSYdpimPZJTCCF0mHaYbDCSUwghdJionEIIIbScdrjmtFxj60m6pY/tj0iaJ2lOXnaTNEbSXcsTd3lImiJpfE/nV1DMF4o4bgghLIvufixlWa7KyXYjX+Z7236m8kTSmOWJWYClzq+apKG2u5p9QiGEUKSBvs+pCMtbOb2Qf64jaWquPu6StGeDrx8jaZqk2XnZLa8fIunHkuZLukrS1ZIOydveK+leSTdJ+pGkq/L6kZLOlTRD0h2SDsjrV5L06zzJ1cXASn2c0wRJN0j6FTAvr7tc0qx8PhOr9n2h6vEhks7PjzeSdGs+l1Mb/kBDCKEJutzd8FKWgbrmdARwre1v5YmnVq7adoOkLmCR7drJpZ4C3mn7FUljgYuA8cAHgTHAVsBawD3AuZJGAD8B9rL9sKSLqo71FeBPtj8qaTRwu6Q/Ap8AXrK9dR54cHbNOdQ7v7c2qlYAAB4BSURBVJ2ALfN06wAftf1PSSuRJtK6tI+BC38InGX755I+3ct+IYTQdJ3UIWIGKXmsCFxue07Vth6bzYAVgTMlbQt0AZvl9XsAv7HdDTwp6Ya8fhzwUFXSuAioVDLvAvaXdFJ+PgLYANgL+BGA7bmS5tacQ73zu70qBsDxkg7Kj9cHxgK9JafdgYPz4wuB0+rtlKuwiQAjh6/FiGGr9XLIEEIYGO3QrDcgycn2VEl7Ae8DLpT0Xds/b+ClnwX+DmxDamJ8Ja+vNz9Ib+sr2w62fd9SK9Mgg/39P/Fi1esnAPsCu9p+SdIUUuKrPe4IltZnzOp5UtZcdbPW/20JIQwK3YO9t16FpA2Bp2yfA/wM2L7Bl64GPJErpH8ljWgLcBNwcL72tDYwIa+/F9i4qlPFoVXHuhb4jHI2krRdXj8VODKv2xLYul9vLp3jszkxjQN2qdr2d0lvkzQEOKhq/c2kYeOpxA4hhFbhfixlGahp2icAcyTdQWrO+mGDr/sxcLSk6aQmvUrFcilpAqu7SNeYbgMW2H4Z+BRwjaSbSFVXZVKiU0nNhHNzV/VKR4SzgFG5Oe8LwO39fG/XACvk158KTK/a9iXgKuBPwBNV608APi1pBim5hRBCy+jGDS9lUavejCVplO0XJL2JlFB2t/1k1XoBk4A/2/5BuWe7/Mpo1lthyNC+dyrAWiNGlxJ3jRWaP6HjXc//tekxy7TasFGlxO20yQafXnBfb5c4+rTLWyY0/H0z/fEpyxVrWbXyCBFX5V53w4BTbT+Z139c0tF5/R2kyiqEEEKDOqm33oCzPaGH9T8A2r5SCiGEsnRMb70QQgjto1Uv51SL5BRCCB0mmvVCCCG0nDKHJWpUJKcQQugwcc0phBBCy2mHESIiObWI17qbPzPHV0bv1PSYAKc9P6uUuA+9+mTfOw2wzUdv0PSYAGutUM79Rne/9Hgpccu45+jxB/+v6TEHSlROIYQQWk5UTiGEEFpOVE4hhBBaTvTWCyGE0HKiWS+EEELLiWa9EEIILcfRrBdCCKHVtMPwRQM12WBLkDRa0qfKPo8QQmhlthteyjKokhMwmjRTbgghhB50ubvhpSyDLTl9B9hE0hxJv5F0QGWDpF9K2l/SMZKukHSNpPskfa1qn6Mk3Z5f/xNJPU4VK+ldkm6VNDvHGpXXPyLplLx+nqRxhb7jEELop2674aURkt6Tv08fkPSlOtsl6Ud5+1xJ2/d1zMGWnL4EPGh7W+BM4FgASasBuwFX5/12Ao4EtgU+JGm8pLcBh5Kmg98W6Mr7vIGkNYGTgX1tbw/MBD5Xtcszef1ZwEkD+xZDCGH5uB//9SX/ET8J2A/YHDhc0uY1u+0HjM3LRNJ3Y68GbYcI2zdKmiRpLeCDwKW2F0sC+IPtfwBIugzYA1gM7ADMyPusBDzVw+F3If1PuDnvOwy4tWr7ZfnnrBy7LkkTSf+jGDFsTYatuOoyvNMQQuifAb6WtBPwgO2HACT9GjgAuLtqnwOAnzsFnp77B6xj+4meDjpok1N2Ian6OQz4aNX62v8zBgRcYPvLDRxXpAR3eA/bF+WfXfTyGdueDEwGWG3UJq3ffSaEMCgMcG+9dYFHq54/BuzcwD7rAj0mp8HWrLcQWKXq+fnAiQC251etf6ekNSStBBwI3AxcDxySKy3y9g17iDMd2F3SpnnflSVtNqDvJIQQCtLV3d3wImmipJlVy8Saw6lOiNrs18g+SxlUlZPtf0i6WdJdwP/Z/ryke4DLa3a9iVRVbQr8yvZMAEknA9dJGgK8Bnwa+EudOE9LOga4SNLwvPpk4P4i3lcIIQyk/jTrVbfw9OAxYP2q5+sBtXOnNLLPUgZVcgKwfUTlsaSVSRfgLqrZ7Snbx9V57cXAxQ3G+ROwY531Y6oezwQmNHK8EEJolgFu1psBjJW0EfA30mWUI2r2+R1wXL4etTOwoLfrTTAIk1OFpH2Bc4Hv215Q9vmEEEKrGMgOEbmj2XHAtcBQ4Fzb8yV9Mm8/m9RT+r3AA8BL5J7UvRm0ycn2H4E3TENq+3zStaiGSLoNGF6z+l9tz1ue8wshhLIM9Kjktq/m9Vt1KuvOrnps0mWShg3a5DRQbNf2OgkhhLYWo5KHEEJoOV3dMSp5CCGEFhOVUwghhJZT5mjjjYrkFEIIHaYdkpPa4SRD7yRNzDfKDeqYEXdwx+2k91pm3HYx2IYv6lS1w4kM1pgRd3DH7aT3WmbcthDJKYQQQsuJ5BRCCKHlRHIaHMpoty6rrTziDt64nfRey4zbFqJDRAghhJYTlVMIIYSWE8kphBBCy4nkFEIIoeVEcgoNy5OJ9bkuLLuqmZV7XVdA3A81si6EZokOEW1I0sbAD4FdgW7gVuCzth8qOO5s29vXrJtle4eC436uzuoFwCzbcwqMOw/eMELmAmAm8E3b/yggZr3P+A3rBkvcTiFpM+DzwIZUDRtne5/STqrFxdh67elXwCTgoPz8MNJU9IXMPSVpHLAFsJqkD1ZtWhUYUUTMGuPzcmV+/j7S1NCflPQb2/9dUNz/A7pInzekzxngedKElR8YqECS/gVYF1hJ0naA8qZVgZUHKk6duPuRZihdV9KPqjatCiwuMO5C3pj4l7C96mCKC/wGOBs4h/Q7FfoQyak9yfaFVc9/kadJLspbgfcDo1n6C3kh8PEC41a8Cdje9gsAkr4GXALsBcwCikpOu9vever5PEk3295d0lEDHOvdwDHAesD/8HpyWgj8xwDHqvY4qRLcn/RZViwEPltUUNurAEj6BvAkcCHpPR8JrDLY4gKLbZ9V4PEHnWjWa0OSvgM8B/ya9FfgoaSp5CcB2P5nQXF3tX1rEcfuI+49wDa2X83PhwNzbL9N0h22tyso7p3ARNu35ec7AefY3qaouJIOtn3pQB+3gbgr2n4tP14dWN/23CbEva12tul669o9rqSvA08BvwUWVdYX9W91MIjKqT0dmn9+omb9R0nJauOC4j4g6T+AMSzdbv7RguJV/AqYLumK/PwDwEWSRgJ3Fxj3Y8C5kkaR/rp+HvhYjvvtgmKuJ2lVUuVyDrA98CXb1xUUr+IPkvYn/X+dAzwt6Ubb9a73DaQuSUfy+h9ah9OcZq9mxz06//x81boi/622vaicQsMk3QJMIzX/LPmH3Iy/9CXtAOxBShI32Z5ZdMyq2KuR/q0814RYd+bK7N3Ap4GvAuc1oUPEHba3k/QxUtX0NUlzbW9dcNwxpM49u5O+rG8GTrT9yGCMGxoXlVMbkrQy8DlgA9sTJY0F3mr7qoJDr2z7iwXHWELSqrafl7QG8HBeKtvWKLD58ijbv6jtJSily0C2v19E3EqY/PO9pKR0pyqBi7WCpHWADwNfaUI8AHIyOKBZ8cqKW+K/2bYVyak9nUeqXnbLzx8j9QYq+hf9KknvtX11wXEqfkXqiDGLpXtYiWKbREbmn0VeIO/JLEnXARsBX5a0Cul2gaJ9A7gWuNn2jHy7wp+LDirpPOr0niu6qbiEuGX9m21b0azXhiTNtD2++qJ8pTmo4LgLSV/ci4DXyEmiwO635Kphfdt/LSpGD3GHAsfb/kGT4w4BtgUesv2cpDcB6zajc0IZJB1c9XQE6faIx20fP5jilvVvtp1F5dSeXpW0EvkvP0mbUNUDqCiVbrjNZNuSfgsUeqNvnbhduYNAU5MT6f/p5qSK8RukPwYKv5cs3yR6FrC27S0lbQ3sb/ubRcatvV4p6SLgj0XGLCluKf9m21kkp/b0deAaYH1JvyRd1D226KCS9qq33vbUgkNPl7Sj7RkFx6l1i6QzgYuBFysrbc8uMOaPSc14+5CS00LgUmDHAmNC6hn4eeAnALbnSvoVUGhyqmMssEGTYzYj7td447/ZYwqM1/aiWa9N5eaeXUhNa9NtP9OEmFdWPR0B7EQaQqjQIVgk3U26EfgRUpKoNCcW3ZPshjqrXeT7rQwZVEKT7QzbO9bEnWN724LjVkZsqFxHfBL4ctE9QMuI29u/WUlb2J5fVOx2FJVTG5J0ve13AL+vs64wtpcarkfS+hQ3OkO1/ZoQ4w1s711C2Nfy9a5K88+baU6HiGdyU1Ml7iHAE0UHLaOpuKy4eSzG3/ew+ULSPW0hi+TURiSNII2ztma+i796/LW3lHBKjwFbNiHOxqSx/QzcbbteRTOgJG1JauZaEhf4nu15BYf+EWkUgbUkfQs4BDi54JiQ7qmaDIyT9DdSt/0jmxC3MiLFWKqurTWhqbi0uD2dTklxW1Y067URSScAJ5IS0d94vUliITDZ9qSC45/B691vK73KHrE90OPMVeKtC1wGvELqhivSX5crAQfZ/ltBcQ8AvkcaBWJmjrsD8GXgJNtX9PLygYg/DnhHjnu97XuKjFcTeyQwxPbCJsX7GHACaUzBOaRmr1ub0FRcStxezidGgK8RyakNSfpP4PR8g+pXSV/YpxZ8oR5JR1c9XUxKTDcXGO+3wBW2z69Z/xHgYNuF3ESZx9Q7oHa0gDyqwBVFXv+RtBUwLj+9x/ZdRcWqivlWYGJ1XNIfO/c3IfY8UmeP6ba3zYn5FNuH9vHStozby/lEcqoRkw22p0NyYtoDeCdp+obCRzy2fQFpao5ZwJ3A7QWH3Lw2MeXz+Dmvf5EWYcV6w9jkdSsWEVDSapKmAJcDR5Ca1K6QdEMea68QknYFppCrb1KvvReBKZJ2KSpulVdsv5LPZbjte0mdXwZr3J68WmLslhTXnNpTZVy79wFn275CadTjQkmaAFxA6jUnUrfYowtspx/aw3kM6WnbAHlN0ga1N/5K2pDi5jg6ldSEuI/t7hxvKKlp8VvAZwqK+5/A4banVK27XNKfSN2fi+6M8pik0aSk/AdJz5Km8ShaU+Pmm8mPBDa2/Q1JGwD/Yvt2ANvN+EOgrUSzXhuSdBXpmtO+pGshLwO3N6G78SzgCNv35eebARe5oJlwJf0AGEUakPPFvG4k6cbYVwq8m/9AUi/E/+L1oZN2BL4EfNH25QXEvBvY2vbimvUrAPNsv22gY+bj3297sx623We7adWEpLcDqwHXOE+PMljiSjqLfP+a01QvqwPX2S76/rW2FZVTe/ow8B5S77Hn8oCdn+/jNQNhxUpiArB9v6RCmrmyL5Aqh79I+ktetwGpeitsAj7bl0t6GPh/pIpFwF3Ah23fWVDYV2sTUz6XxZKKHEmgt44PL/aybbnlCniu7S0BbN9YZLyS4+5cuX8tx3xW0rAmxG1bkZzakO2XSL3YKs+foAn3pAAzJf2MdE8GpGaKWb3sv1ycJr87KXf62JSUJB7I779QOQl9BEDSKOdZeAs0QktPz14h0kSSRVlfS0/PXh133QLjYrtb0p31mlAHYdyy7l9rW5GcQn/8O+l+mONJX15TScPtFE3AgaTpBj6uJk03kDsL/IzUtLiBpG2AT9j+VAHhngB6morjyQLiVfRWcTdjzqx1gPmSbmfpIaL2H2RxK/evrd3k+9faVlxzCi1P0sWkCu0jeVDSlUj3pBQ9tM5tpC+R31UN6XNXpTloMJI0snJ9r0nx3l5vfdFNbWXErbp/DeBPzbx/rR1F5RQaJun9pF5lG5J+dwqfMiPbxPahkg4nBXw5934qnO1Ha0IVOoW4SpqUrslVIpJ2sT29WdeZyo6brUzqZWrSjeShF3GfU+iP04GjgTfZXtX2Kk1ITFDedAOPStoNsKRhkk4i3aBapPNI97xUT0rXjJHBTwfeDfwDllxzqzsK/QBZ0hws6dYC47RE3Hzj/AXAGsCawHmSolmvF1E5hf54FLjLzW8LLmu6gU8CPyR1DHgMuI50za1InVIlVgcqfL6qFoh7OLBd1Y2/3wFm0/wpSdpGJKfQH18ArpZ0I1WVi+2eLuQPCNt/kDSb16cbOMFNmCIkx2jK4KdVWqJKJHV6KbJKHJLv9RlS9XhJ4rD9z0EW9xFSMnwlPx8OPFhQrEEhOkSEhkm6DngBmEdVN1jbpxQc9yDSBeQF+floYEIRN8PWxL2AlAify89XB/7H9kcLjPlOUi+uzUmV2u7AMTUjOBQRd01Slbgv6cv6OtJ7/0dB8R4h/Q7Vqwpte+NBFvdy0o3cfyD94fFO4CbgqRy40Gnp21Ekp9AwSTNtjy8h7hsmvVPVpHgFxn1DjCbFbfpEkqFYWnrQ5DfI41aGKtGsF/rjj5LeZfu6Jset13GnGb+7QyStbvtZAElrFB23qkr8fX4+WtKBg7FKzHF2B+bYflHSUaQR9k8v6uZYSb2O/O3iRvb/B3B1ZdzE0LeonELDlKa2Hkm6BvIaTepKLulc4DlgEqlJ5DPA6raPKTjuR0hzOF2SV30I+JbtC3t+1XLH7LQqcS6wDbA1aeSRnwEftF33PqQBiFeZqHIEMJ40ur5y/Nts71FQ3F8AuwKXAufFPU59i8opNMz2Krl6WGr20Cb4DPBV4GJevx5SdK85bP88D3a7d477Qdt3Fxy2Y6rEbLFtK03w+EPbP+urCWx52N4bQNKvgYnOMxsrzXx8UoFxj1Ka+uRwUjdyk24buMhNmtix3UTlFBqm+rOH3mL7Hb2+sI3l8dDWpuqLusjx2DqpSsxxbyTdJnAs6b6qp0nNfFsVHLdehfqGdQXEXRM4ijSj9T2kMSN/ZPuMIuO2o0hOoWEqb9bSzUh/1Y5h6SRR9FTenyHdY/V30j0/lWbMrQuMOZJUJVb3mvtmM4YUkrQFr1eJ1zehSkTSv5AmV5xhe5rSPEcTnCaULDLuRaQx9X5B+iPgKGCU7cMLirc/KQFvQmq+vMD2U3lEkHtsb1hE3HYWySk0TNIM2ztKmkOaAmBRk/7avBM4mzS+3pIbQ20XNiJ6jvsA6X0W0p261TS7SiyTpBGkgYwro2BMBc6q3CRbQLyLgUmumphT0mm2vyjpHbavLyJuO4trTqE/ypq1dLHtwqehr+NRYEEzA7ZalUjqKFBEvJts75E72VT/hdyUTja2X5F0NqkH3X19vmD5jfUbZ4zejzR5ZSSmOqJyCstETZy1VGkK+qdIUw5Uj0xR1N38lbg/A94K/J4mjYgRVWJz5Ga27wLDbG8kaVvgGx7gKTMk/TvwKWBjlh4RYhXgZttHDWS8wSSSU2h5SrPS1irsbv6quF+rt77IETEkzXJB0973EfcG4J2uMxvvYJR7Ye4DTPHr06HMHejriZJWA1Ynzej8papNC4v+46rdRbNeaHm2NyopbqHDMvXgSkmfoslVIvAQMEVS06rEki22vaDoMXXzkFsLSF3IQz9EcgptId+HsjlV91c1oUfXm0mD3W5RE7fI6z+Ve3yqZ6g1qVmoSH/Ny7C8DHZ3SToCGKo0Z9bxwC0ln1OoEs16oeXl5rUJpOR0NelC8k22Dyk47nWkG39PIk2fcTTwtO0vFhk3FC934f4K8C5SJ4xrgVOL6q0X+i+SU2h5+f6qbYA7bG8jaW3gp7Y/UHDcWbZ3qL4WIenGoobWqYrbKVViCD2KZr3QDl623S1pcR4C5imKb+aCNH4gwBOS3kfqNr9ekQF7qhKBQpMT8EtSlfh+qqrEgmOWRtKVLN2FHdK1oZnAT6KCKl9M0x7awcx8f9U5pC7Ws4HbmxD3m7m31f8jNe39FPhswTEPAd4BPGn7WFLFOLzgmABvsv0z4DXbN+bRyHdpQtyyPESam+ycvDxPusdrs/w8lCwqp9DybH8qPzxb0jXAqrbnNiHuVfnhAtKwPs3QMVViybazvVfV8yslTbW9l6T5pZ1VWCKSU2hZvc29I2n7oubekXQGb2zyWcLFzlpaWyW+QPOrxDOAVSm+SizTmyVtUBmeKY/pt2beVuhN5aEx0SEitKyquXfqcVEX61tl1lJJY2hSldhpJL2XNBLHg6TeehuRRnKYAnzc9unlnV2ASE4htISyZmgtuUoslaThwDhScro3OkG0lmjWC22hxO7VX6wTt4iK7X962WbSUDtFmFnQcVuapA/WrNpY0gJgnu2nyjinsLSonELLi5tww0DLwzTtCvyJVDlNAKaTeut9o+hJFkPfonIK7eAQXr8J99jKTbhNiPumPG34CbZvBG7MM7cWqgOqxFbQDbzN9t8B8u/UWcDOpLmdIjmVLO5zCu3gZdvdQKndqyVtR3Nuwj0jL3sD/w0M6DQOPfgladrwjYBTgEeAGU2IW5YxlcSUPQVslgfYfa2H14QmisoptINO6l7dUVViiaZJugr4TX5+MDBV0kjgufJOK1TENafQVgZ792pJt9veKc83tDewELjL9hYFx51uexdJ1wI/It2Ee4ntTYqMWxaluTIOBnYnXXO6CbjU8YXYMqJyCi1N0gpAl21LWh8Yz9IzihYRcwRwKPAscCVpQNQ9c9xTbT9TYPhOqhJLk5PQJXkJLSgqp9CyJH0cOI30BX0qaY6j2cB2wLm2Tyso7v+SrjuMJM1iehcpSe0BbGv7/UXErXMeYxjEVWKZJO1CSsJvI81fNRR40faqpZ5YWCKSU2hZeYyzPYBVSBfrN7T9TJ6LZ0ZRTV2S7rK9Za7aHrP9L1Xb7rS9TUFxa6vEnYEHbd9RRLwcs8wqsTSSZgKHka45jQc+Amxq+yulnlhYInrrhVb2qu1n8/hnD1S+KG2/RLHjn72a4ywmXXup1lVEwFwlPgX8JT++ntQ54teSiryv6uekCfc+Shq6ZwPgTNK1rvMLjFs62w8AQ2132T6P5g3uGxoQ15xCK1spd98eAgzLj5WXEb2+cvmsJ+lHOU7lMfn5ugXFPBHYhB6qRFLzZhE2r6kSKxMpXiPpzoJitoKXJA0D5kj6b+AJUjNuaBGRnEIrexL4fp3HledF+XzV49rhfYoa7udV288Cz0paqkqU1JQqUVJTqsQW8a+k60zHkTp+rE/qvRdaRCSn0LJsTygp7gUAkja2/VCTwnZSlVg623/JD18m3XQcWkx0iAgtq87gnEuxfVnB8aeSvqBnkIa0mWZ7XkGxptD76OCFXA9plelBmkXSPHr/nLdu4umEXkRyCi1L0nn54VrAbqRBOiFduJ5iu9fkNUDnMAzYkTQw6CeAUbbXKDpuszW5SiyNpA17215VUYWSRbNeaFm2jwXIw8xsbvuJ/HwdYFLR8SXtQepWvScwGrgKmFZQrFKrROB8SU2pEku2ju3pZZ9E6FtUTqHlVe47qno+BJhbva6guF2kDhDfBq62XVjHhKgSm0PSbNvb58e32t617HMK9UXlFNrBlDzm20Wk6wWHAb1N4T5Q3kQae20v4HhJ3cCttr860IE6qUosmaoeF9nRJCynSE6h5dk+Ljd77ZlXTbb92ybEfU7SQ6RuxuuRKpoVCw47ppKYsr+TJsAr2o00qUos2RBJq5N6RVYeL0lYecqM0AKiWS+EHkh6ELiPNGL1NOC2or+0JZ0JjGXpKvEB258pOO5oXq8SdyRNxldIlVgmSY+Q3pvqbLbtZswTFhoQySm0LEkLSV/QYunuvyJ9kRQ6SKekIXmSw6aqqRKnNqNKzHHfBrw9x94N+GvViBEhNFUkp9AWJG3L0l/YhQ+tI2kz0tTda+chfrYG9rf9zaJjN1sZVWKZJO0OzLH9oqSjgO2B0/M4jqEFRHIKLU/S8cDHgctIVdOBwDm2zyg47o2koYx+Ynu7vG6pnoMDGKsjq8SySJpLmnF4a+BC4GfAB6NSbB3RISK0g48Bu9h+EUDSacCtpPl4irSy7dvTpKlLLC4ikO1VKo/LqBKBTSV1RJWYLc5TkxwA/DBPUd/raBmhuWLKjNAOxNKDkHZR/4L2QHtG0ibkSkbSIaTRqwuTq8QLgTWBNwMXSiq0M0R2DvBl0iSL5AkOD2tC3LIslPRl4Cjg95KGUnxPzNAPUTmFdnAecJukSseAA0nNMEX7NDAZGCfpb8DDwJEFxxz0VWKLOBQ4Avg3209K2gD4bsnnFKpEcgotz/b388Coe5AqpmOLnB22yt9IifEGYA3geeBo4BsFxuyYKrFMtpeagiV3hPh5eWcUakVyCm3B9mxgdpPDXgE8l+PWznVUlE6qEptO0k2296jqgLJkE03oeBIaF731QuhBUT3zGoi7Pa9XiVObUSVKGk6aFn4Mr1eJtl1klRhCj6JyCqFnt0jaqtmjc3dQlRhCj6JyCqEHku4GNiU1cS3i9aafQTchXVlVYgg9icophJ7tV/YJNFEpVWIIPYnKKYTQUVViaA+RnEIIPU5fHtOWh7JEcgohhNByYviiEEIILSeSUwghhJYTySmEEELLieQUQgih5URyCiGE0HL+P0t+nZwnAS4/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, X_test, y_train_res, y_test = train_test_split(X, y, random_state = 123, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define resampling\n",
    "over = SMOTE(random_state = 123, sampling_strategy = 0.008)\n",
    "under = RandomUnderSampler(random_state = 123, sampling_strategy = 0.5)\n",
    "# define pipeline\n",
    "pipeline = Pipeline(steps=[('o', over), ('u', under)])\n",
    "#pipeline = Pipeline(steps=[('o', over)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int64), array([39774, 19887], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59656</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59657</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59658</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59659</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59660</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59661 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       step  type_en\n",
       "0         9      0.0\n",
       "1        19      0.0\n",
       "2        15      0.0\n",
       "3         9      0.0\n",
       "4         9      0.0\n",
       "...     ...      ...\n",
       "59656     1      1.0\n",
       "59657    15      0.0\n",
       "59658     1      1.0\n",
       "59659    14      1.0\n",
       "59660     3      0.0\n",
       "\n",
       "[59661 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and apply the pipeline\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_train_res, y_train_res)\n",
    "print(np.unique(y_resampled, return_counts = True))\n",
    "pd.DataFrame(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy' : 'accuracy', 'precision' : 'precision', 'recall' : 'recall', 'f1' : 'f1', 'auc' : 'roc_auc' , 'specificity' : make_scorer(recall_score, pos_label=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats = 3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "imba_pipeline = make_pipeline(SMOTE(random_state = 123, sampling_strategy = 0.008), RandomUnderSampler(random_state = 123, sampling_strategy = 0.5), CategoricalNB())\n",
    "hasil_awal = cross_validate(imba_pipeline, X_train_res, y_train_res, scoring=scoring, cv=cv_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_awal_df = pd.concat([pd.DataFrame(hasil_awal[\"test_accuracy\"], columns=[\"accuracy\"]), pd.DataFrame(hasil_awal[\"test_precision\"], columns=[\"precision\"]), pd.DataFrame(hasil_awal[\"test_recall\"], columns=[\"recall\"]), pd.DataFrame(hasil_awal[\"test_f1\"], columns=[\"f1\"]), pd.DataFrame(hasil_awal[\"test_auc\"], columns=[\"auc\"]), pd.DataFrame(hasil_awal[\"test_specificity\"], columns=[\"specificity\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_awal_df['fpr'] = 1- hasil_awal_df['specificity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.957756</td>\n",
       "      <td>0.031967</td>\n",
       "      <td>0.453930</td>\n",
       "      <td>0.059727</td>\n",
       "      <td>0.808760</td>\n",
       "      <td>0.959250</td>\n",
       "      <td>0.040750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.014996</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.956745</td>\n",
       "      <td>0.030141</td>\n",
       "      <td>0.428765</td>\n",
       "      <td>0.056323</td>\n",
       "      <td>0.796372</td>\n",
       "      <td>0.958198</td>\n",
       "      <td>0.039920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.957519</td>\n",
       "      <td>0.031159</td>\n",
       "      <td>0.441316</td>\n",
       "      <td>0.058209</td>\n",
       "      <td>0.802125</td>\n",
       "      <td>0.959041</td>\n",
       "      <td>0.040455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.957752</td>\n",
       "      <td>0.031975</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.059794</td>\n",
       "      <td>0.807348</td>\n",
       "      <td>0.959240</td>\n",
       "      <td>0.040760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.958082</td>\n",
       "      <td>0.032879</td>\n",
       "      <td>0.464043</td>\n",
       "      <td>0.061409</td>\n",
       "      <td>0.813730</td>\n",
       "      <td>0.959545</td>\n",
       "      <td>0.040959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.958602</td>\n",
       "      <td>0.034344</td>\n",
       "      <td>0.487110</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.824546</td>\n",
       "      <td>0.960080</td>\n",
       "      <td>0.041802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision     recall         f1        auc  specificity  \\\n",
       "count  30.000000  30.000000  30.000000  30.000000  30.000000    30.000000   \n",
       "mean    0.957756   0.031967   0.453930   0.059727   0.808760     0.959250   \n",
       "std     0.000443   0.001102   0.014996   0.002048   0.008453     0.000438   \n",
       "min     0.956745   0.030141   0.428765   0.056323   0.796372     0.958198   \n",
       "25%     0.957519   0.031159   0.441316   0.058209   0.802125     0.959041   \n",
       "50%     0.957752   0.031975   0.454545   0.059794   0.807348     0.959240   \n",
       "75%     0.958082   0.032879   0.464043   0.061409   0.813730     0.959545   \n",
       "max     0.958602   0.034344   0.487110   0.064164   0.824546     0.960080   \n",
       "\n",
       "             fpr  \n",
       "count  30.000000  \n",
       "mean    0.040750  \n",
       "std     0.000438  \n",
       "min     0.039920  \n",
       "25%     0.040455  \n",
       "50%     0.040760  \n",
       "75%     0.040959  \n",
       "max     0.041802  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil_awal_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score =  0.7918573272321953\n",
      "precision score =  0.8497050285607266\n",
      "recall score =  0.4562779705335144\n",
      "f1 score =  0.5937315971995027\n",
      "roc auc score =  0.707962488057525\n",
      "Specificity :  0.9596470055815357\n"
     ]
    }
   ],
   "source": [
    "gnb = CategoricalNB().fit(X_resampled, y_resampled)\n",
    "pred1 = gnb.predict(X_resampled)\n",
    "print('accuracy score = ', accuracy_score(y_resampled, pred1))\n",
    "print('precision score = ', precision_score(y_resampled, pred1))\n",
    "print('recall score = ', recall_score(y_resampled, pred1))\n",
    "print('f1 score = ', f1_score(y_resampled, pred1))\n",
    "print('roc auc score = ', roc_auc_score(y_resampled, pred1))\n",
    "cm = confusion_matrix(y_resampled, pred1)\n",
    "specificity1 = cm[0,0]/(cm[0,1]+cm[0,0])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33018</td>\n",
       "      <td>6756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7892</td>\n",
       "      <td>11995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  33018   6756\n",
       "1   7892  11995"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 100 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py:506: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "[Parallel(n_jobs=1)]: Done 3000 out of 3000 | elapsed: 284.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17080.728505373\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "np.random.seed(999)\n",
    "\n",
    "#gb = GaussianNB()\n",
    "\n",
    "params = {\"classifier__class_prior\": [None, [0.5,0.5], [0.6,0.4], [0.7, 0.3], [0.8, 0.2], [0.9, 0.1]],\n",
    "              \"classifier__alpha\": np.linspace(0, 1),\n",
    "                \"classifier__fit_prior\" : [True, False]}\n",
    "\n",
    "#params_NB = {'priors': [None, [0.5,0.5], [0.6,0.4], [0.7, 0.3], [0.8, 0.2], [0.9, 0.1]], 'var_smoothing':np.logspace(0, -9)}\n",
    "imba_pipeline2 = Pipeline([('smote', SMOTE(random_state = 123, sampling_strategy = 0.008)), \n",
    "                           ('under', RandomUnderSampler(random_state = 123, sampling_strategy = 0.5)),\n",
    "                           ('classifier', CategoricalNB())])\n",
    "\n",
    "\n",
    "gs_NB2 = RandomizedSearchCV(imba_pipeline2, \n",
    "                     param_distributions=params, \n",
    "                     cv=cv_method,\n",
    "                     n_iter = 100,\n",
    "                     verbose=1, \n",
    "                     scoring=scoring, refit = 'recall')\n",
    "\n",
    "\n",
    "#X_resampled, y_resampled = pipeline.fit_resample(X_train_res, y_train_res)\n",
    "#X_transformed = PowerTransformer().fit_transform(X_resampled)\n",
    "\n",
    "gs_NB2.fit(X_train_res, y_train_res)\n",
    "time_elapsed = (time.time() - time_start)\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.concat([pd.DataFrame(gs_NB2.cv_results_[\"params\"]),pd.DataFrame(gs_NB2.cv_results_[\"mean_test_accuracy\"], columns=[\"mean_accuracy\"]), pd.DataFrame(gs_NB2.cv_results_[\"mean_test_precision\"], columns=[\"mean_precision\"]), pd.DataFrame(gs_NB2.cv_results_[\"mean_test_recall\"], columns=[\"mean_recall\"]), pd.DataFrame(gs_NB2.cv_results_[\"mean_test_f1\"], columns=[\"mean_f1\"]), pd.DataFrame(gs_NB2.cv_results_[\"mean_test_auc\"], columns=[\"mean_auc\"]), pd.DataFrame(gs_NB2.cv_results_[\"mean_test_specificity\"], columns=[\"mean_specificity\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2['mean_fpr'] = 1 - result2['mean_specificity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__fit_prior': True, 'classifier__class_prior': [0.5, 0.5], 'classifier__alpha': 0.9591836734693877}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier__alpha</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>mean_precision</th>\n",
       "      <th>mean_recall</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>mean_specificity</th>\n",
       "      <th>mean_fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.541020</td>\n",
       "      <td>0.914608</td>\n",
       "      <td>0.040860</td>\n",
       "      <td>0.503502</td>\n",
       "      <td>0.068822</td>\n",
       "      <td>0.808765</td>\n",
       "      <td>0.915827</td>\n",
       "      <td>0.084173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.297253</td>\n",
       "      <td>0.079924</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.051372</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.080554</td>\n",
       "      <td>0.080554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.332295</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808760</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.007237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.280612</td>\n",
       "      <td>0.893873</td>\n",
       "      <td>0.015661</td>\n",
       "      <td>0.395667</td>\n",
       "      <td>0.030451</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.894872</td>\n",
       "      <td>0.020175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540816</td>\n",
       "      <td>0.957756</td>\n",
       "      <td>0.031967</td>\n",
       "      <td>0.453930</td>\n",
       "      <td>0.059727</td>\n",
       "      <td>0.808766</td>\n",
       "      <td>0.959250</td>\n",
       "      <td>0.040750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.978099</td>\n",
       "      <td>0.055021</td>\n",
       "      <td>0.557017</td>\n",
       "      <td>0.096597</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.979825</td>\n",
       "      <td>0.105128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.120309</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.176475</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.992763</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       classifier__alpha  mean_accuracy  mean_precision  mean_recall  \\\n",
       "count         100.000000     100.000000      100.000000   100.000000   \n",
       "mean            0.541020       0.914608        0.040860     0.503502   \n",
       "std             0.297253       0.079924        0.035887     0.134454   \n",
       "min             0.000000       0.780086        0.009582     0.332295   \n",
       "25%             0.280612       0.893873        0.015661     0.395667   \n",
       "50%             0.540816       0.957756        0.031967     0.453930   \n",
       "75%             0.795918       0.978099        0.055021     0.557017   \n",
       "max             1.000000       0.990811        0.120309     0.716289   \n",
       "\n",
       "          mean_f1    mean_auc  mean_specificity    mean_fpr  \n",
       "count  100.000000  100.000000        100.000000  100.000000  \n",
       "mean     0.068822    0.808765          0.915827    0.084173  \n",
       "std      0.051372    0.000002          0.080554    0.080554  \n",
       "min      0.018911    0.808760          0.780275    0.007237  \n",
       "25%      0.030451    0.808763          0.894872    0.020175  \n",
       "50%      0.059727    0.808766          0.959250    0.040750  \n",
       "75%      0.096597    0.808767          0.979825    0.105128  \n",
       "max      0.176475    0.808767          0.992763    0.219725  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_NB2.best_params_)\n",
    "result2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71428571, 0.95918367, 0.85714286, 0.16326531, 0.14285714,\n",
       "       0.04081633, 0.91836735, 0.46938776, 0.67346939, 0.93877551,\n",
       "       0.63265306, 0.34693878, 0.69387755, 0.87755102, 0.89795918,\n",
       "       0.40816327, 0.32653061, 0.79591837, 0.83673469, 0.3877551 ,\n",
       "       0.06122449, 0.24489796, 0.        , 0.97959184, 0.81632653,\n",
       "       0.30612245, 0.7755102 , 0.75510204, 0.12244898, 0.53061224,\n",
       "       0.08163265, 0.42857143, 0.2244898 , 0.44897959, 0.26530612,\n",
       "       0.28571429, 0.36734694, 1.        , 0.73469388, 0.65306122,\n",
       "       0.55102041, 0.51020408])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2['classifier__alpha'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier__fit_prior</th>\n",
       "      <th>classifier__class_prior</th>\n",
       "      <th>classifier__alpha</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>mean_precision</th>\n",
       "      <th>mean_recall</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>mean_specificity</th>\n",
       "      <th>mean_fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808766</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.9, 0.1]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.120309</td>\n",
       "      <td>0.332295</td>\n",
       "      <td>0.176475</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.992763</td>\n",
       "      <td>0.007237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.9, 0.1]</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.120309</td>\n",
       "      <td>0.332295</td>\n",
       "      <td>0.176475</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.992763</td>\n",
       "      <td>0.007237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.9, 0.1]</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.120309</td>\n",
       "      <td>0.332295</td>\n",
       "      <td>0.176475</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.992763</td>\n",
       "      <td>0.007237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.9, 0.1]</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.120309</td>\n",
       "      <td>0.332295</td>\n",
       "      <td>0.176475</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.992763</td>\n",
       "      <td>0.007237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.9, 0.1]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.120309</td>\n",
       "      <td>0.332295</td>\n",
       "      <td>0.176475</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.992763</td>\n",
       "      <td>0.007237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    classifier__fit_prior classifier__class_prior  classifier__alpha  \\\n",
       "70                   True              [0.5, 0.5]           0.530612   \n",
       "1                    True              [0.5, 0.5]           0.959184   \n",
       "89                  False                    None           0.857143   \n",
       "94                  False              [0.5, 0.5]           0.408163   \n",
       "4                    True              [0.5, 0.5]           0.142857   \n",
       "..                    ...                     ...                ...   \n",
       "47                   True              [0.9, 0.1]           0.142857   \n",
       "5                   False              [0.9, 0.1]           0.040816   \n",
       "41                   True              [0.9, 0.1]           0.387755   \n",
       "97                  False              [0.9, 0.1]           0.346939   \n",
       "74                  False              [0.9, 0.1]           0.142857   \n",
       "\n",
       "    mean_accuracy  mean_precision  mean_recall   mean_f1  mean_auc  \\\n",
       "70       0.780086        0.009582     0.716289  0.018911  0.808766   \n",
       "1        0.780086        0.009582     0.716289  0.018911  0.808763   \n",
       "89       0.780086        0.009582     0.716289  0.018911  0.808763   \n",
       "94       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "4        0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "..            ...             ...          ...       ...       ...   \n",
       "47       0.990811        0.120309     0.332295  0.176475  0.808767   \n",
       "5        0.990811        0.120309     0.332295  0.176475  0.808767   \n",
       "41       0.990811        0.120309     0.332295  0.176475  0.808767   \n",
       "97       0.990811        0.120309     0.332295  0.176475  0.808767   \n",
       "74       0.990811        0.120309     0.332295  0.176475  0.808767   \n",
       "\n",
       "    mean_specificity  mean_fpr  \n",
       "70          0.780275  0.219725  \n",
       "1           0.780275  0.219725  \n",
       "89          0.780275  0.219725  \n",
       "94          0.780275  0.219725  \n",
       "4           0.780275  0.219725  \n",
       "..               ...       ...  \n",
       "47          0.992763  0.007237  \n",
       "5           0.992763  0.007237  \n",
       "41          0.992763  0.007237  \n",
       "97          0.992763  0.007237  \n",
       "74          0.992763  0.007237  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedResult = result2.sort_values(['mean_specificity'], axis = 0, ascending= False).sort_values(['mean_recall'], axis = 0, ascending= False)\n",
    "sortedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Performansi hasil \textit{tuning parameter} algoritme \textit{gaussian naive bayes}}\n",
      "\\label{resGauss}\n",
      "\\begin{tabular}{llrrrrrrrr}\n",
      "\\toprule\n",
      " classifier\\_\\_fit\\_prior & classifier\\_\\_class\\_prior &  classifier\\_\\_alpha &  mean\\_accuracy &  mean\\_precision &  mean\\_recall &   mean\\_f1 &  mean\\_auc &  mean\\_specificity &  mean\\_fpr \\\\\n",
      "\\midrule\n",
      "                  True &              [0.5, 0.5] &           0.530612 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808766 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.959184 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808763 &          0.780275 &  0.219725 \\\\\n",
      "                 False &                    None &           0.857143 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808763 &          0.780275 &  0.219725 \\\\\n",
      "                 False &              [0.5, 0.5] &           0.408163 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.142857 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.693878 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808764 &          0.780275 &  0.219725 \\\\\n",
      "                 False &                    None &           0.734694 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808764 &          0.780275 &  0.219725 \\\\\n",
      "                 False &              [0.5, 0.5] &           0.530612 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808766 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.326531 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                 False &                    None &           0.224490 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                 False &                    None &           0.632653 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808764 &          0.780275 &  0.219725 \\\\\n",
      "                 False &                    None &           0.408163 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.040816 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                 False &                    None &           0.469388 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808766 &          0.780275 &  0.219725 \\\\\n",
      "                 False &              [0.5, 0.5] &           0.122449 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                 False &              [0.5, 0.5] &           0.714286 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808764 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.918367 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808763 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.897959 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808763 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.224490 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.387755 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                 False &                    None &           0.000000 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808767 &          0.780275 &  0.219725 \\\\\n",
      "                 False &                    None &           0.795918 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808763 &          0.780275 &  0.219725 \\\\\n",
      "                  True &              [0.5, 0.5] &           0.632653 &       0.780086 &        0.009582 &     0.716289 &  0.018911 &  0.808764 &          0.780275 &  0.219725 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.285714 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808767 &          0.894872 &  0.105128 \\\\\n",
      "                  True &              [0.6, 0.4] &           0.428571 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808766 &          0.894872 &  0.105128 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.714286 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808764 &          0.894872 &  0.105128 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.551020 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808766 &          0.894872 &  0.105128 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.265306 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808767 &          0.894872 &  0.105128 \\\\\n",
      "                  True &              [0.6, 0.4] &           0.775510 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808764 &          0.894872 &  0.105128 \\\\\n",
      "                  True &              [0.6, 0.4] &           0.061224 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808767 &          0.894872 &  0.105128 \\\\\n",
      "                  True &              [0.6, 0.4] &           0.673469 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808764 &          0.894872 &  0.105128 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.367347 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808767 &          0.894872 &  0.105128 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.408163 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808767 &          0.894872 &  0.105128 \\\\\n",
      "                  True &              [0.6, 0.4] &           0.979592 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808760 &          0.894872 &  0.105128 \\\\\n",
      "                  True &              [0.6, 0.4] &           0.877551 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808763 &          0.894872 &  0.105128 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.673469 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808764 &          0.894872 &  0.105128 \\\\\n",
      "                  True &              [0.6, 0.4] &           0.306122 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808767 &          0.894872 &  0.105128 \\\\\n",
      "                  True &              [0.6, 0.4] &           0.040816 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808767 &          0.894872 &  0.105128 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.510204 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808766 &          0.894872 &  0.105128 \\\\\n",
      "                 False &              [0.6, 0.4] &           0.938776 &       0.893873 &        0.015661 &     0.557017 &  0.030451 &  0.808763 &          0.894872 &  0.105128 \\\\\n",
      "                  True &                    None &           0.551020 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808766 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.959184 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808763 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.469388 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808766 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.693878 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808764 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.755102 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808764 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.224490 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808767 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.346939 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808767 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.816327 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808763 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.448980 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808766 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.918367 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808763 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.408163 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808767 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.163265 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808767 &          0.959250 &  0.040750 \\\\\n",
      "                  True &                    None &           0.877551 &       0.957756 &        0.031967 &     0.453930 &  0.059727 &  0.808763 &          0.959250 &  0.040750 \\\\\n",
      "                 False &              [0.7, 0.3] &           0.959184 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808763 &          0.959852 &  0.040148 \\\\\n",
      "                 False &              [0.7, 0.3] &           0.897959 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808763 &          0.959852 &  0.040148 \\\\\n",
      "                  True &              [0.7, 0.3] &           0.408163 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808767 &          0.959852 &  0.040148 \\\\\n",
      "                  True &              [0.7, 0.3] &           0.265306 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808767 &          0.959852 &  0.040148 \\\\\n",
      "                 False &              [0.7, 0.3] &           0.081633 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808767 &          0.959852 &  0.040148 \\\\\n",
      "                 False &              [0.7, 0.3] &           0.979592 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808760 &          0.959852 &  0.040148 \\\\\n",
      "                  True &              [0.7, 0.3] &           0.142857 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808767 &          0.959852 &  0.040148 \\\\\n",
      "                  True &              [0.7, 0.3] &           0.061224 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808767 &          0.959852 &  0.040148 \\\\\n",
      "                  True &              [0.7, 0.3] &           0.469388 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808766 &          0.959852 &  0.040148 \\\\\n",
      "                 False &              [0.7, 0.3] &           0.857143 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808763 &          0.959852 &  0.040148 \\\\\n",
      "                  True &              [0.7, 0.3] &           0.755102 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808764 &          0.959852 &  0.040148 \\\\\n",
      "                 False &              [0.7, 0.3] &           0.673469 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808764 &          0.959852 &  0.040148 \\\\\n",
      "                 False &              [0.7, 0.3] &           0.163265 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808767 &          0.959852 &  0.040148 \\\\\n",
      "                  True &              [0.7, 0.3] &           0.775510 &       0.958353 &        0.032432 &     0.452528 &  0.060509 &  0.808764 &          0.959852 &  0.040148 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.081633 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808767 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.244898 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808767 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.8, 0.2] &           0.693878 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808764 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.857143 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808763 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.8, 0.2] &           0.673469 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808764 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.775510 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808764 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.8, 0.2] &           0.224490 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808767 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.224490 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808767 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.795918 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808763 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.8, 0.2] &           0.714286 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808764 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.8, 0.2] &           0.428571 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808766 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.8, 0.2] &           1.000000 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808760 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.8, 0.2] &           0.877551 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808763 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.448980 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808766 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.387755 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808767 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.632653 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808764 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.265306 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808767 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.8, 0.2] &           0.836735 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808763 &          0.979825 &  0.020175 \\\\\n",
      "                 False &              [0.8, 0.2] &           0.918367 &       0.978099 &        0.055021 &     0.395667 &  0.096597 &  0.808763 &          0.979825 &  0.020175 \\\\\n",
      "                  True &              [0.9, 0.1] &           0.653061 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808764 &          0.992763 &  0.007237 \\\\\n",
      "                  True &              [0.9, 0.1] &           0.714286 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808764 &          0.992763 &  0.007237 \\\\\n",
      "                  True &              [0.9, 0.1] &           1.000000 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808760 &          0.992763 &  0.007237 \\\\\n",
      "                  True &              [0.9, 0.1] &           0.979592 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808760 &          0.992763 &  0.007237 \\\\\n",
      "                 False &              [0.9, 0.1] &           0.897959 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808763 &          0.992763 &  0.007237 \\\\\n",
      "                 False &              [0.9, 0.1] &           0.632653 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808764 &          0.992763 &  0.007237 \\\\\n",
      "                  True &              [0.9, 0.1] &           0.938776 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808763 &          0.992763 &  0.007237 \\\\\n",
      "                  True &              [0.9, 0.1] &           0.061224 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808767 &          0.992763 &  0.007237 \\\\\n",
      "                 False &              [0.9, 0.1] &           0.448980 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808766 &          0.992763 &  0.007237 \\\\\n",
      "                  True &              [0.9, 0.1] &           0.142857 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808767 &          0.992763 &  0.007237 \\\\\n",
      "                 False &              [0.9, 0.1] &           0.040816 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808767 &          0.992763 &  0.007237 \\\\\n",
      "                  True &              [0.9, 0.1] &           0.387755 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808767 &          0.992763 &  0.007237 \\\\\n",
      "                 False &              [0.9, 0.1] &           0.346939 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808767 &          0.992763 &  0.007237 \\\\\n",
      "                 False &              [0.9, 0.1] &           0.142857 &       0.990811 &        0.120309 &     0.332295 &  0.176475 &  0.808767 &          0.992763 &  0.007237 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sortedResult.to_latex(index = False, caption = \"Performansi hasil \\textit{tuning parameter} algoritme \\textit{gaussian naive bayes}\", label = \"resGauss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier__fit_prior</th>\n",
       "      <th>classifier__class_prior</th>\n",
       "      <th>classifier__alpha</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>mean_precision</th>\n",
       "      <th>mean_recall</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>mean_specificity</th>\n",
       "      <th>mean_fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808764</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808764</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808766</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808766</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808764</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808766</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808764</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808763</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808764</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808767</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classifier__fit_prior classifier__class_prior  classifier__alpha  \\\n",
       "1                    True              [0.5, 0.5]           0.959184   \n",
       "45                  False                    None           0.224490   \n",
       "89                  False                    None           0.857143   \n",
       "84                  False                    None           0.734694   \n",
       "78                  False              [0.5, 0.5]           0.714286   \n",
       "72                   True              [0.5, 0.5]           0.897959   \n",
       "71                   True              [0.5, 0.5]           0.224490   \n",
       "70                   True              [0.5, 0.5]           0.530612   \n",
       "61                   True              [0.5, 0.5]           0.040816   \n",
       "53                  False                    None           0.469388   \n",
       "46                  False                    None           0.632653   \n",
       "37                  False              [0.5, 0.5]           0.530612   \n",
       "4                    True              [0.5, 0.5]           0.142857   \n",
       "36                  False              [0.5, 0.5]           0.122449   \n",
       "34                  False                    None           0.408163   \n",
       "29                   True              [0.5, 0.5]           0.918367   \n",
       "27                   True              [0.5, 0.5]           0.632653   \n",
       "24                  False                    None           0.000000   \n",
       "20                   True              [0.5, 0.5]           0.387755   \n",
       "17                  False                    None           0.795918   \n",
       "16                   True              [0.5, 0.5]           0.326531   \n",
       "12                   True              [0.5, 0.5]           0.693878   \n",
       "94                  False              [0.5, 0.5]           0.408163   \n",
       "\n",
       "    mean_accuracy  mean_precision  mean_recall   mean_f1  mean_auc  \\\n",
       "1        0.780086        0.009582     0.716289  0.018911  0.808763   \n",
       "45       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "89       0.780086        0.009582     0.716289  0.018911  0.808763   \n",
       "84       0.780086        0.009582     0.716289  0.018911  0.808764   \n",
       "78       0.780086        0.009582     0.716289  0.018911  0.808764   \n",
       "72       0.780086        0.009582     0.716289  0.018911  0.808763   \n",
       "71       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "70       0.780086        0.009582     0.716289  0.018911  0.808766   \n",
       "61       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "53       0.780086        0.009582     0.716289  0.018911  0.808766   \n",
       "46       0.780086        0.009582     0.716289  0.018911  0.808764   \n",
       "37       0.780086        0.009582     0.716289  0.018911  0.808766   \n",
       "4        0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "36       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "34       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "29       0.780086        0.009582     0.716289  0.018911  0.808763   \n",
       "27       0.780086        0.009582     0.716289  0.018911  0.808764   \n",
       "24       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "20       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "17       0.780086        0.009582     0.716289  0.018911  0.808763   \n",
       "16       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "12       0.780086        0.009582     0.716289  0.018911  0.808764   \n",
       "94       0.780086        0.009582     0.716289  0.018911  0.808767   \n",
       "\n",
       "    mean_specificity  mean_fpr  \n",
       "1           0.780275  0.219725  \n",
       "45          0.780275  0.219725  \n",
       "89          0.780275  0.219725  \n",
       "84          0.780275  0.219725  \n",
       "78          0.780275  0.219725  \n",
       "72          0.780275  0.219725  \n",
       "71          0.780275  0.219725  \n",
       "70          0.780275  0.219725  \n",
       "61          0.780275  0.219725  \n",
       "53          0.780275  0.219725  \n",
       "46          0.780275  0.219725  \n",
       "37          0.780275  0.219725  \n",
       "4           0.780275  0.219725  \n",
       "36          0.780275  0.219725  \n",
       "34          0.780275  0.219725  \n",
       "29          0.780275  0.219725  \n",
       "27          0.780275  0.219725  \n",
       "24          0.780275  0.219725  \n",
       "20          0.780275  0.219725  \n",
       "17          0.780275  0.219725  \n",
       "16          0.780275  0.219725  \n",
       "12          0.780275  0.219725  \n",
       "94          0.780275  0.219725  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2[ (result2['mean_recall'] >= 0.7)].sort_values(['mean_recall'], axis = 0, ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "imba_pipeline = make_pipeline(SMOTE(random_state = 123, sampling_strategy = 0.008), RandomUnderSampler(random_state = 123, sampling_strategy = 0.5), CategoricalNB(class_prior=[0.5,0.5], alpha = 0.530612, fit_prior =True))\n",
    "hasil = cross_validate(imba_pipeline, X_train_res, y_train_res, scoring=scoring, cv=cv_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_df = pd.concat([pd.DataFrame(hasil[\"test_accuracy\"], columns=[\"accuracy\"]), pd.DataFrame(hasil[\"test_precision\"], columns=[\"precision\"]), pd.DataFrame(hasil[\"test_recall\"], columns=[\"recall\"]), pd.DataFrame(hasil[\"test_f1\"], columns=[\"f1\"]), pd.DataFrame(hasil[\"test_auc\"], columns=[\"auc\"]), pd.DataFrame(hasil[\"test_specificity\"], columns=[\"specificity\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>specificity</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.780086</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.716289</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.808766</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.219725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.016592</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.008452</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>0.009098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.772232</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.678426</td>\n",
       "      <td>0.017848</td>\n",
       "      <td>0.796376</td>\n",
       "      <td>0.772446</td>\n",
       "      <td>0.206879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.773195</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.708277</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.802125</td>\n",
       "      <td>0.773352</td>\n",
       "      <td>0.208354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.773951</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.715739</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.807351</td>\n",
       "      <td>0.774101</td>\n",
       "      <td>0.225899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.791467</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>0.726594</td>\n",
       "      <td>0.019435</td>\n",
       "      <td>0.813730</td>\n",
       "      <td>0.791646</td>\n",
       "      <td>0.226648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.792911</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.753053</td>\n",
       "      <td>0.020389</td>\n",
       "      <td>0.824558</td>\n",
       "      <td>0.793121</td>\n",
       "      <td>0.227554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision     recall         f1        auc  specificity  \\\n",
       "count  30.000000  30.000000  30.000000  30.000000  30.000000    30.000000   \n",
       "mean    0.780086   0.009582   0.716289   0.018911   0.808766     0.780275   \n",
       "std     0.009049   0.000356   0.016592   0.000693   0.008452     0.009098   \n",
       "min     0.772232   0.009039   0.678426   0.017848   0.796376     0.772446   \n",
       "25%     0.773195   0.009299   0.708277   0.018360   0.802125     0.773352   \n",
       "50%     0.773951   0.009504   0.715739   0.018764   0.807351     0.774101   \n",
       "75%     0.791467   0.009855   0.726594   0.019435   0.813730     0.791646   \n",
       "max     0.792911   0.010338   0.753053   0.020389   0.824558     0.793121   \n",
       "\n",
       "             fpr  \n",
       "count  30.000000  \n",
       "mean    0.219725  \n",
       "std     0.009098  \n",
       "min     0.206879  \n",
       "25%     0.208354  \n",
       "50%     0.225899  \n",
       "75%     0.226648  \n",
       "max     0.227554  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil_df['fpr'] = 1-hasil_df['specificity']\n",
    "hasil_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the pipeline\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_train_res, y_train_res)\n",
    "gnb = CategoricalNB(class_prior=[0.5,0.5], alpha = 0.530612, fit_prior =True).fit(X_resampled, y_resampled)\n",
    "pred1 = gnb.predict(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score =  0.7637652737969528\n",
      "precision score =  0.6299519942572569\n",
      "recall score =  0.7060391210338413\n",
      "f1 score =  0.6658289074355083\n",
      "roc auc score =  0.7493337356061749\n",
      "Specificity =  0.7926283501785085\n",
      "fpr :  0.20737164982149148\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score = ', accuracy_score(y_resampled, pred1))\n",
    "print('precision score = ', precision_score(y_resampled, pred1))\n",
    "print('recall score = ', recall_score(y_resampled, pred1))\n",
    "print('f1 score = ', f1_score(y_resampled, pred1))\n",
    "print('roc auc score = ', roc_auc_score(y_resampled, pred1))\n",
    "cm = confusion_matrix(y_resampled, pred1)\n",
    "specificity1 = cm[0,0]/(cm[0,1]+cm[0,0])\n",
    "print('Specificity = ', specificity1)\n",
    "print('fpr : ', 1-specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31526</td>\n",
       "      <td>8248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5846</td>\n",
       "      <td>14041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  31526   8248\n",
       "1   5846  14041"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5848499</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338416</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627064</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561811</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285299</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323609</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273983</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456451</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907111</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990730</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step  type_en\n",
       "5848499    18      0.0\n",
       "6338416    19      0.0\n",
       "3627064    10      0.0\n",
       "1561811    11      0.0\n",
       "4285299    19      0.0\n",
       "...       ...      ...\n",
       "3323609    13      0.0\n",
       "1273983    15      0.0\n",
       "3456451    17      1.0\n",
       "1907111    22      0.0\n",
       "1990730    11      0.0\n",
       "\n",
       "[277041 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score =  0.7916409484516732\n",
      "precision score =  0.010398016802093376\n",
      "recall score =  0.7156398104265402\n",
      "f1 score =  0.020498201316771873\n",
      "roc auc score =  0.7537565011936754\n",
      "Specificity =  0.7918731919608106\n",
      "fpr :  0.20812680803918937\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score = ', accuracy_score(y_test, pred1))\n",
    "print('precision score = ', precision_score(y_test, pred1))\n",
    "print('recall score = ', recall_score(y_test, pred1))\n",
    "print('f1 score = ', f1_score(y_test, pred1))\n",
    "print('roc auc score = ', roc_auc_score(y_test, pred1))\n",
    "cm = confusion_matrix(y_test, pred1)\n",
    "specificity1 = cm[0,0]/(cm[0,1]+cm[0,0])\n",
    "print('Specificity = ', specificity1)\n",
    "print('fpr : ', 1-specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218713</td>\n",
       "      <td>57484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0  218713  57484\n",
       "1     240    604"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88    276197\n",
      "           1       0.01      0.72      0.02       844\n",
      "\n",
      "    accuracy                           0.79    277041\n",
      "   macro avg       0.50      0.75      0.45    277041\n",
      "weighted avg       1.00      0.79      0.88    277041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
